{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95105c8a-c203-4bf2-8286-372b4f7ebb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e39636-8166-44dc-9c3a-06a441599903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reunion = pd.read_csv('data/reunion_train.csv')\n",
    "reunion_test = pd.read_csv('data/reunion_test_X.csv')\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f8503a-5c67-4a0d-a445-6ec4cebbb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source_ID_column = df_reunion['Source ID']\n",
    "df_reunion = df_reunion.drop(columns=['Source ID'])\n",
    "\n",
    "Source_ID_column_test = reunion_test['Source ID']\n",
    "reunion_test = reunion_test.drop(columns=['Source ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8be89562-bdcb-4029-abd1-f19080c4bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reunion.columns = [s.strip().replace(' ', '_').lower() for s in df_reunion.columns]\n",
    "reunion_test.columns = [s.strip().replace(' ', '_').lower() for s in reunion_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09106946-1c38-40ce-a809-95be8db36675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to datetime\n",
    "df_reunion['event_date'] = pd.to_datetime(df_reunion['event_date'], format=\"%m/%d/%y\", errors='coerce')\n",
    "df_reunion['original_response_date_(gmt)'] = pd.to_datetime(df_reunion['original_response_date_(gmt)'], format=\"%Y-%m-%dT%H:%M:%S.%fZ\", errors='coerce')\n",
    "\n",
    "reunion_test['event_date'] = pd.to_datetime(reunion_test['event_date'], format=\"%m/%d/%y\", errors='coerce')\n",
    "reunion_test['original_response_date_(gmt)'] = pd.to_datetime(reunion_test['original_response_date_(gmt)'], format=\"%Y-%m-%dT%H:%M:%S.%fZ\", errors='coerce')\n",
    "\n",
    "# Remove timezone information from the 'last_registration_date_(gmt)' column\n",
    "df_reunion['original_response_date_(gmt)'] = df_reunion['original_response_date_(gmt)'].dt.tz_localize(None)\n",
    "\n",
    "reunion_test['original_response_date_(gmt)'] = reunion_test['original_response_date_(gmt)'].dt.tz_localize(None)\n",
    "\n",
    "# Calculate the difference in days\n",
    "df_reunion['days_registered_prior_to_event'] = (df_reunion['event_date'] - df_reunion['original_response_date_(gmt)']).dt.days\n",
    "\n",
    "reunion_test['days_registered_prior_to_event'] = (reunion_test['event_date'] - reunion_test['original_response_date_(gmt)']).dt.days\n",
    "\n",
    "# Use np.maximum to ensure no negative values\n",
    "df_reunion['days_registered_prior_to_event'] = np.maximum(df_reunion['days_registered_prior_to_event'], 0)\n",
    "\n",
    "reunion_test['days_registered_prior_to_event'] = np.maximum(reunion_test['days_registered_prior_to_event'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fffb52b7-c3a1-4ce2-917e-e1d5b63cfda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Days Registered Prior to the Event is within 2 weeks (14 days)\n",
    "df_reunion['regist_within_2_weeks'] = df_reunion['days_registered_prior_to_event'] <= 14\n",
    "\n",
    "reunion_test['regist_within_2_weeks'] = reunion_test['days_registered_prior_to_event'] <= 14\n",
    "# Check if Days Registered Prior to the Event is within 1 month (30 days)\n",
    "df_reunion['regist_within_1_month'] = df_reunion['days_registered_prior_to_event'] <= 30\n",
    "\n",
    "reunion_test['regist_within_1_month'] = reunion_test['days_registered_prior_to_event'] <= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfe96c4-257c-4e40-acf7-6db7ceaa8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attended column: Yes - 1, No - 0\n",
    "df_reunion['attended'] = [1 if value == 'Yes' else 0 for value in df_reunion['attended']]\n",
    "\n",
    "# regist_within_2_weeks column: True - 1, False - 0\n",
    "df_reunion['regist_within_2_weeks'] = [1 if value == True else 0 for value in df_reunion['regist_within_2_weeks']]\n",
    "\n",
    "reunion_test['regist_within_2_weeks'] = [1 if value == True else 0 for value in reunion_test['regist_within_2_weeks']]\n",
    "\n",
    "# regist_within_1_month column: True - 1, False - 0\n",
    "df_reunion['regist_within_1_month'] = [1 if value == True else 0 for value in df_reunion['regist_within_1_month']]\n",
    "\n",
    "reunion_test['regist_within_1_month'] = [1 if value == True else 0 for value in reunion_test['regist_within_1_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a173eaa-04fa-4455-8367-855cfd820c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "df_reunion = df_reunion.drop(columns=['event_title', 'bertrand_society', 'last_modified_date_(gmt)','last_registration_date_(gmt)', 'event_check-in_time_(gmt)', 'invitee_status', 'invitee/guest'])\n",
    "reunion_test = reunion_test.drop(columns=['event_title', 'bertrand_society', 'last_modified_date_(gmt)','last_registration_date_(gmt)', 'event_check-in_time_(gmt)', 'invitee_status', 'invitee/guest'])\n",
    "\n",
    "# Replace NaN values with the most frequent value (mode) of the column\n",
    "reunion_mode_train = df_reunion['reunion_years_out/reunion_anniversary'].mode()[0]\n",
    "df_reunion['reunion_years_out/reunion_anniversary'].fillna(reunion_mode_train, inplace=True)\n",
    "\n",
    "reunion_mode_test = reunion_test['reunion_years_out/reunion_anniversary'].mode()[0]\n",
    "reunion_test['reunion_years_out/reunion_anniversary'].fillna(reunion_mode_test, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfcfdd4b-6589-4044-a98d-de81a024faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count commas in each cell\n",
    "def count_commas(cell):\n",
    "    return str(cell).count(',')\n",
    "\n",
    "# Create new columns for each original column to store comma counts for 'student_activities'\n",
    "for cell in df_reunion['student_activities']:\n",
    "    df_reunion[\"student_act_comma_count\"] = df_reunion['student_activities'].apply(count_commas)\n",
    "for cell in reunion_test['student_activities']:\n",
    "    reunion_test[\"student_act_comma_count\"] = reunion_test['student_activities'].apply(count_commas)\n",
    "\n",
    "# Create new columns for each original column to store comma counts for 'all_constituencies'\n",
    "for cell in df_reunion['all_constituencies']:\n",
    "    df_reunion[\"constituencies_comma_count\"] = df_reunion['all_constituencies'].apply(count_commas)\n",
    "for cell in reunion_test['all_constituencies']:\n",
    "    reunion_test[\"constituencies_comma_count\"] = reunion_test['all_constituencies'].apply(count_commas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ab2f49-fc04-468c-988a-16234dbea246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to indicate if there is a value (1) or not (0) in 'greek_affiliation'\n",
    "df_reunion['greek_presence'] = df_reunion['greek_affiliation'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)\n",
    "reunion_test['greek_presence'] = reunion_test['greek_affiliation'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)\n",
    "\n",
    "# Create a new column to indicate if there is a value (1) or not (0) in 'varsity_sports'\n",
    "df_reunion['varsity_presence'] = df_reunion['varsity_sports'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)\n",
    "reunion_test['varsity_presence'] = reunion_test['varsity_sports'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)\n",
    "\n",
    "# Create a new column to indicate if there is a value (1) or not (0) in 'primary_state/prov.'\n",
    "df_reunion['state_known'] = df_reunion['primary_state/prov.'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)\n",
    "reunion_test['state_known'] = reunion_test[ 'primary_state/prov.'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)\n",
    "\n",
    "# Create a new column to indicate if there is a value (1) or not (0) in 'current_volunteer_activities'\n",
    "df_reunion['volunteering'] = df_reunion['current_volunteer_activities'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)\n",
    "reunion_test['volunteering'] = reunion_test['current_volunteer_activities'].apply(lambda x: 1 if pd.notnull(x) and str(x).strip() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d029fcf2-416e-4ffd-89c3-588f69287b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign values based on degree type: Arts - 1, Engineering - 2, Business - 3, and Unknown - 0\n",
    "def assign_degree_value(degree):\n",
    "    if isinstance(degree, str):  # Check for str values only\n",
    "        degree = degree.lower()  # Convert to lowercase\n",
    "        if 'admin' in degree:\n",
    "            return 'mgmt'\n",
    "        elif 'engin' in degree or 'engr' in degree:\n",
    "            return 'engr'\n",
    "        elif 'arts' in degree or 'science' in degree:\n",
    "            return 'art&s'\n",
    "        else:\n",
    "            return 'art&s'\n",
    "    else:\n",
    "        return 0 # For NaN values\n",
    "\n",
    "# Create Degree Type column\n",
    "df_reunion['degree_type'] = df_reunion['bucknell_degrees'].apply(assign_degree_value)\n",
    "reunion_test['degree_type'] = reunion_test['bucknell_degrees'].apply(assign_degree_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aee01e8-cf53-4882-95cd-289cf232c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR TRAINING DATA\n",
    "\n",
    "# Create dummy variables for 'degree_type' and drop the first column\n",
    "degree_dummies = pd.get_dummies(df_reunion['degree_type'], drop_first=True)\n",
    "\n",
    "# Make it binary True - 1 and False - 0\n",
    "degree_dummies = degree_dummies.astype(int)\n",
    "\n",
    "# Add to the original DataFrame\n",
    "df_reunion = pd.concat([df_reunion, degree_dummies], axis=1)\n",
    "\n",
    "# Drop the Degree Type column to not have redundancy\n",
    "df_reunion = df_reunion.drop(columns=['degree_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "837b44e5-902c-4fdf-beed-54526743d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR TEST DATA\n",
    "\n",
    "# Create dummy variables for 'degree_type' and 'major_type' and drop the first column\n",
    "degree_dummies = pd.get_dummies(reunion_test['degree_type'], drop_first=True)\n",
    "\n",
    "# Make it binary True - 1 and False - 0\n",
    "degree_dummies = degree_dummies.astype(int)\n",
    "\n",
    "# Add to the original DataFrame\n",
    "reunion_test = pd.concat([reunion_test, degree_dummies], axis=1)\n",
    "\n",
    "# Drop the Degree Type column to not have redundancy\n",
    "reunion_test = reunion_test.drop(columns=['degree_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f8e64e2-56fe-4d1c-8a64-c66d374723b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all the NaN values with Unknown\n",
    "df_reunion['bucknell_majors'] = df_reunion['bucknell_majors'].fillna('Unknown')\n",
    "reunion_test['bucknell_majors'] = reunion_test['bucknell_majors'].fillna('Unknown')\n",
    "\n",
    "# Container for checking index -- Unknown already added for consistent indexing\n",
    "majors_list = ['Unknown']\n",
    "\n",
    "# Assign values based on major type. People with same majors get assigned the same value\n",
    "def assign_UNQmajor_value(major):\n",
    "    if isinstance(major, str):  # Check for str values only\n",
    "        major = major.lower()   # Convert to lowercase\n",
    "        if major[:6] not in majors_list:\n",
    "            majors_list.append(major[:6])\n",
    "            return majors_list.index(major[:6])\n",
    "        elif major[:6] in majors_list:\n",
    "            return majors_list.index(major[:6])\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create Major type column\n",
    "df_reunion['major_type'] = df_reunion['bucknell_majors'].apply(assign_UNQmajor_value)\n",
    "reunion_test['major_type'] = reunion_test['bucknell_majors'].apply(assign_UNQmajor_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "902be72b-2989-4c26-91b5-b7088d11f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all the NaN values with Unknown\n",
    "df_reunion['ethnicity'] = df_reunion['ethnicity'].fillna('Unknown')\n",
    "reunion_test['ethnicity'] = reunion_test['ethnicity'].fillna('Unknown')\n",
    "\n",
    "# Container for checking index\n",
    "ethnicity_list = []\n",
    "\n",
    "# Assign values based on ethnicity. People with same ethnicity get assigned the same value\n",
    "def assign_UNQethnicity_value(ethnicity):\n",
    "    if isinstance(ethnicity, str):  # Check for str values only\n",
    "        ethnicity = ethnicity.lower()   # Convert to lowercase\n",
    "        if ethnicity[:6] not in ethnicity_list:\n",
    "            ethnicity_list.append(ethnicity[:6])\n",
    "            return ethnicity_list.index(ethnicity[:6])\n",
    "        elif ethnicity[:6] in ethnicity_list:\n",
    "            return ethnicity_list.index(ethnicity[:6])\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Create ethnicity_known column\n",
    "df_reunion['ethnicity_known'] = df_reunion['ethnicity'].apply(assign_UNQethnicity_value)\n",
    "reunion_test['ethnicity_known'] = reunion_test['ethnicity'].apply(assign_UNQethnicity_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20aaddf7-e328-4fc9-9216-c30d16267b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['bucknell_class_year', 'ethnicity_known','major_type', 'volunteering', 'art&s', 'engr', 'mgmt', 'state_known', 'constituencies_comma_count', 'greek_presence', 'varsity_presence', 'student_act_comma_count', 'days_registered_prior_to_event', 'regist_within_2_weeks', 'regist_within_1_month', 'reunion_years_out/reunion_anniversary']\n",
    "y_train = df_reunion['attended']\n",
    "x_train = df_reunion[predictors]\n",
    "x_test = reunion_test[predictors]\n",
    "\n",
    "x_train = x_train.fillna(0)\n",
    "x_test = x_test.fillna(0)\n",
    "\n",
    "# select the df_reunion columns that are objects and typecast them to category\n",
    "cat_cols = x_train.select_dtypes(include='object').columns\n",
    "x_train[cat_cols] = x_train[cat_cols].astype('category')\n",
    "x_test[cat_cols] = x_test[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c03f19bd-0c58-45ff-88a6-67a1815abb1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2,003'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Predict probabilities for the test data\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m test_probabilities \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict_proba(x_test)[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Probabilities for positive class\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Add probabilities to the test dataset\u001b[39;00m\n\u001b[1;32m     21\u001b[0m reunion_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_probability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_probabilities\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py:578\u001b[0m, in \u001b[0;36mPipeline.predict_proba\u001b[0;34m(self, X, **predict_proba_params)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    577\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m--> 578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict_proba(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_proba_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1383\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1375\u001b[0m ovr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     )\n\u001b[1;32m   1381\u001b[0m )\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[0;32m-> 1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_predict_proba_lr(X)\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1385\u001b[0m     decision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_base.py:466\u001b[0m, in \u001b[0;36mLinearClassifierMixin._predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    460\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \n\u001b[1;32m    462\u001b[0m \u001b[38;5;124;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;124;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m     prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X)\n\u001b[1;32m    467\u001b[0m     expit(prob, out\u001b[38;5;241m=\u001b[39mprob)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prob\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2,003'"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep numerical columns as is\n",
    ")\n",
    "\n",
    "# Define Logistic Regression pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the test data\n",
    "test_probabilities = pipeline.predict_proba(x_test)[:, 1]  # Probabilities for positive class\n",
    "\n",
    "# Add probabilities to the test dataset\n",
    "reunion_test['predicted_probability'] = test_probabilities\n",
    "\n",
    "# Output the test dataset with predictions\n",
    "print(reunion_test[['predicted_probability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45f69eb-55a3-463d-8307-55fba8fc1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predicted probabilities on the training data for AUC evaluation\n",
    "train_probabilities = pipeline.predict_proba(x_train)[:, 1]\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_train, train_probabilities)\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_train, train_probabilities)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a128842-3edb-4512-b83b-19cc5aa93d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reunion_test_original = pd.read_csv('data/reunion_test_X.csv')\n",
    "\n",
    "source_id_test = reunion_test_original['Source ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate the submission file in the required format\n",
    "submission = pd.DataFrame({\n",
    "    'Source ID': source_id_test,\n",
    "    'Attend_Likelihood': test_probabilities\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_file_path = 'Downloads/reunion_submission(v1).csv'\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "\n",
    "print(f\"Submission file saved at: {submission_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928dce64-8a37-41e8-bdaa-cc6c2a096aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
